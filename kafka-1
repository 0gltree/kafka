#!/bin/bash

# express Intellectual Property Rights
cat <<EOT

#########################################
#   This script was developed by Taos   #
#     for use by Taos                   #
#     to service xAd alerts             #
#     regarding Kafka disk space.       #
#   It is the property of Taos,         #
#     and Taos reserves all rights      #
#     to this script.                   #
#########################################

EOT

# read config file
dN=$( dirname $0 )													# path to config file based on calling path to this file.
. $dN/kafka.cfg														# source the config file


if [ -f ~/kafkaHost ]													# if this file exists
then
	AWSHost=$(cat ~/kafkaHost)											# read file as name of host in trouble
	echo "read kafkaHost=$AWSHost"											# announce it
else															# just starting up so ..
	echo "Please tell me the host server to check."									# for now we'll ask for hostname
	read AWSHost													# get input from operator
fi
# Ticket has:  "Host: xAd-Kafka-US-VPC-52.90.24.184"
# we need:                        "ec2-52-90-24-184.compute-1.amazonaws.com"
pre=$(echo $AWSHost |cut -c -3)												# isolate the first 3 characters
echo "pre=$pre"
if [ "$pre" != "ec2" ]													# if not "ec2" then should be translated
then
	if [ "$pre" != "xAd" ]
	then
		echo "expecting xAd- or ec2- type of server name"
		echo "aborting due to unknown type"
		exit 1
	fi
	Ipa=$( echo $AWSHost |awk -F\- '{print $NF}' |awk -F\. '{print $1"-"$2"-"$3"-"$4}' )				# get the numeric tuples as hyphenated IP address
	Regn=$( echo $AWSHost |awk -F\- '{print $3}' )									# get 2 letter region
	if [ "$Regn" != "US" -a "$Regn" != "AP" -a "$Regn" != "EU" -a "$Regn" != "CN" ]
	then
		echo "expected US, AP, EU, or CN but got $Regn - aborting!"
		exit 1
	fi
	eDC=$( cat /etc/defaultcluster )										# get the name of the default cluster for this bastion server
	Cn=$( echo $eDC |cut -c $(( $( echo $eDC |wc -c ) -3 ))- )							# isolate the cluster number from the default cluster name
	RCn=${!Regn}
	Pnodes=$( for i in $RCn;do er -e %{kafka$i} |grep $Ipa; done )
	nPn=$( echo $Pnodes |wc -w |awk '{print $1}' )
	if [ $nPn -eq 0 ]
	then
		echo "Cannot find a host with that IP"
		exit 1
	else
		if [ $nPn -gt 1 ]
		then
			echo "Found $nPn nodes with that IP"
			echo $Pnodes
			for i in $Pnodes
			do
				iN=$(echo $i |awk -F. '{print $2}' |sed "s/-//g")
				if [ ${!iN} -ne $Cn ]									# if not in this region
				then
					cR=$(ssh -A ${BH[${!iN}]} "ssh -A $i \"df -h |grep -i 'data' |tail -1\"")	# jump through bastion server in correct region to get DF info
				else
					cR=$(ssh -A $i "df -h |grep -i 'data' |tail -1")
				fi
				pDf=$(echo $cR |awk '{print $5}' |awk -F\% '{print $1}')				# isolate the numric value only
				if [ $pDf -ge $ADFL ]
				then
					if [ ${!iN} -ne $Cn ]
					then
						echo "You must login to ${BH[${!iN}]} and run kafka-1 from there"	# explain need to use bastion server in correct region
						exit 0
					else
						newHost=$i
						break
					fi
				fi
			done
			tHost=$( echo $Pnodes |grep $newHost )
			if [ "$tHost" = "" ]
			then
				echo "Unable to determine correct Kafka host"
				exit 1
			fi
			Pnodes=$newHost
		fi
	fi
	AWSHost=$Pnodes
echo "AWSHost=$AWSHost"
	echo "Using $AWSHost"
else															# we have ec2-<IP> form but still need to verify reachability
	eDC=$( cat /etc/defaultcluster )										# get the name of the default cluster for this bastion server
	Cn=$( echo $eDC |cut -c $(( $( echo $eDC |wc -c ) -3 ))- )							# isolate the cluster number from the default cluster name
	R=$(echo $AWSHost |awk -F\. '{print $2}' |sed "s/-//g")
echo "R=$R  ${!R}  Cn=$Cn  ${BH[${!R}]}"
fi

R=$( echo $AWSHost |awk -F. '{print $2}' )										# isolate region

case "$R" in
	"compute-1")		R="us-east-1"
				RN=$USE1
		;;
	"us-east-1")		RN=$USE1
		;;
	"ap-northeast-1")	RN=$APNE1
		;;
	"eu-west-1")		RN=$EUW1
		;;
	"us-west-2")		RN=$USW2
		;;
	"cn-north-1")		RN=$CNN1
		;;
esac
echo "$R -> $RN"													# us-west-2 -> 701
nB=$(echo ${BH[$RN]} |wc -w |awk '{print $1}')
rI=$(echo $(( $RANDOM % $nB +1 )) )
bastion=$(echo "${BH[$RN]}" |head -$rI |tail -1)
echo "bastion=$bastion"
if [ "$eDC" != "bastion$RN" ]												# if this is not the bastion server (run from taos.us-east-1.xad.com)
then
	echo "Transferring to $bastion"											# announce intention to migrate
	scp kafka[.-][c1]* ${bastion}:~											# copy files to bastion server
	ssh -A $bastion "/bin/echo -n $AWSHost >kafkaHost"								# create kafkaHost file to pass name of problem host
	ssh -A $bastion ~/kafka-1											# run kafka-1 on bastion server to actually fix the problem
	ssh -A $bastion "rm ~/*"											# clean-up: remove all files from bastion server
	exit 0														# We are done here
fi
# if this is now being run on the bastion server from the "ssh -A $bastion ~/kafka-1" line above (4 up from here)
# then it will continue in the main section following all of the function declarations.

#############################
#                           #
#  SUBROUTINES - FUNCTIONS  #
#                           #
#############################
function Calc
{	echo $(( $1 ))
	if [ $? -ne 0 ]; then exit 1; fi
}

function jumpFail
{	if [ $? -ne 0 ]
	then
		echo "failed twice trying to execute command via jumphost"
		echo "suggest checking remote access first, then retry script."
		exit 1
	fi
}

function tryTwice													# try to perform a remote command at most 2 times
{	err=1														# init err for entering while loop
	nt=0														# init try count for while loop
	while [ $err -ne 0  -a  $nt -ne 2 ]
	do
		Z=$( ssh -A $HN "$1" )											# run the command
		err=$?													# grab the returned status code
		nt=$( Calc "nt + 1" )											# increment number of tries count
	done
	if [ $err -ne 0 ]
	then
		echo "Failed twice trying to execute command via ssh to $HN" >/dev/stderr
		echo "Command: $1" >/dev/stderr
		echo "Suggest checking remote access first, then retry script." >/dev/stderr
		exit 1
	else
		echo $Z													# for calls expecting to assign a variable to the results
	fi
}

function setVdirs
{	V=$( tryTwice "rpm -q -a |grep kafka |grep conf |awk -F\. '{print \$2}' |awk -F- '{print \$1}' |head -1" )	# only one kafka conf install allowed
	if [ "$V" = "8" ]
	then
		DD=$DD8;	BD=$BD8;	CD=$CD8
	else
		DD=$DD10;	BD=$BD10;	CD=$CD10
	fi
	dP=$(tryTwice "sudo grep log.dir ${CD}/server.properties |grep -v \# |awk -F= '{print \$2}' |sed \"s/,/ /g\"")	# data dir must be determined by what is being used
	nDp=$( echo $dP |wc -w |awk '{print $1}')									# might be more than one data dir specified
	if [ $nDp -gt 1 ]
	then														# find the one with the most files in it
		oNdF=0
		for i in $dP
		do
			nDf=$(tryTwice "sudo ls -al $i |wc -l |awk '{print $1}'")
			if [ $nDf -gt 5 ]
			then
				if [ $nDf -gt $oNdF ]
				then
					DD=$i
					oNdF=$nDf
				fi
			fi
		done
	else														# only one data dir specified in server.properties
		res=$(echo $dP |grep xad)
		if [ "$res" != "" ]											# likely to be sybolic link, want direct path
		then
			nC=$(echo $dP |wc -c |awk '{print $1}')								# number of characters in path to data dir
			nL=$( echo $dP |awk -F/ '{print $NF}' |wc -c |awk '{print $1}')					# number of characters in last dir in path
			tC=$( Calc "$nC - $nL -1" )									# number of characters in path to parent of data dir
			pD=$( echo $dP |cut -c 1-$tC )									# parent dir of data dir where we might find link
			DD=$( tryTwice "sudo ls -l $pD |grep kafka.data |awk '{print \$NF}'")				# get path to true data dir
		else
			DD=$dP
		fi
	fi
	echo "DataDir=$DD   BinDir=$BD   ConfigDir=$CD"
}

function getDF
{	TMPs="df -h $DD |grep -i data |awk '{print \$5}' |awk -F% '{print \$1}'"
	DF=$( tryTwice "$TMPs" )
	if [ $? -eq 0 ]
	then
		if [ "$DF" = "" ]
		then
			echo "Couldn't get DF for $DD"
			echo "Should escalate."
			exit 0
		fi
		echo "$DD DF=${DF} % full"
		return 0
	else
		echo "problem getting DF of /data"
		DF=-1
		return 1
	fi
}

function getTopic
{	if [ $Lvl -eq 1 ]
	then
		L=$( tail -2 kafka_DiskUsage.out |head -1 )								# get largest partition
	else
		L=$( grep -v "${T2}-[0-9]" kafka_DiskUsage.out |tail -2 |head -1 )					# get second largest partition
		echo "L=$L"
	fi
	L1=$( echo $L |awk -F/ '{print $NF}' )										# strip off directory info.
	L2=$( echo $L |awk -F- '{print $NF}' |wc -c |awk '{print $1}' )							# number of characters after the last '-' (partition number)
	nc=$( echo $L1 |wc -c |awk '{print $1}' )									# number of characters in string
	lot=$( Calc "$nc - $L2 -1" )											# number of characters in topic string (without partition)
	T=$( echo $L1 |cut -c -$lot )											# topic string without directory or partition info.
}

function getPartitionInfo
{	err=0
	B=$( tryTwice "sudo su - xad -c '${BD}/kafka-topics.sh --zookeeper $ZKS --topic $T --describe |grep -v \"Configs:\"' " )
	B=$( echo $B |sed "s/.Last login.*//" )
	rm -f kafka_partitionInfo.out
	if [ -e "kafka_partitionInfo.out" ]; then return 1; fi
	y=0
	for u in $B
	do
		if [ "$u" = "Topic:" -a $y -ne 0 ]
		then
			echo "" >> kafka_partitionInfo.out
			err=${err}||$?
		fi
		/bin/echo -n " $u" >> kafka_partitionInfo.out
		err=${err}||$?
		y=$( Calc "$y + 1" )
	done
	testTopic=$( head -1 kafka_partitionInfo.out |awk '{print $2}' )
	if [ "$testTopic" != "$T" ]
	then
		echo "Failed to get new partitionInfo for $T - got $testTopic instead."
		return 1
	fi
	return $err
}

function getBrokerIDs
{	err=0
	C=$( tryTwice "er -e %${edc}:KAFKA_BROKERID |grep -v login " )							# get the Broker ID info
	rm -f kafka_BIDs.out												# remove any old file
	if [ -e "kafka_BIDs.out" ]; then return 1; fi									# verify removal
	for i in $C; do  echo $i >> kafka_BIDs.out;  err=$(( $err | $? ));  done					# write the data to new file
	return $err
}

function getDuInfo
{	err=0
# get disk usage info for topic partitions.
	P=$( tryTwice "du -h $DD |sort -h |grep -iv 'last login'" )
# P has all the results on one line. We need to reformat to individual lines per entry.
	r[0]="  "                                                                                                       # spaces between the first and second part of each line
	r[1]="
"                                                                                                                       # linefeed after the second entry to split into multiple lines.
	j=0                                                                                                             # initial state of flip-flop
# clean up format & save to file for later
	for i in $P
	do
		/bin/echo -n "${i}${r[$j]}" >> kafka_DiskUsage.out							# output part of the line, spaces after first part and LF after second part.
		err=$(( $err | $? ))
		j=$( Calc "1 - $j" )                                                                                    # flip-flop (1-0=1, 1-1=0) to switch between spaces and linefeed
	done
	return $err
}

function isItRebuilt
{	fE=$( tryTwice "sudo su - xad -c \"ls ${DD}/* |grep $REBUILT\" |egrep -iv 'last login|no such file'" )
	if [ "$fE" != "" ]												# if the edge case flag file exists
	then
		echo "This seems to be a special case where the host was rebuilt."
		echo "You should do this by hand, as I am not yet equipped to handle it."
		exit 0													# can return zero to handle normally
	fi
	return 1													# not a rebuilt condition - so recommend escalation
}

function round
{
	n=${SL[$j]}
	rem=$( echo $n |awk -F\. '{print $2}' )										# get any fractional part
	if [ "$rem" != "" ]												# if there is fractional part
	then
		int=$( echo $n |awk -F\. '{print $1$2}' )								# effectively *10
		n=$( echo $(( $int + 5 )) )										# effectively add .5
		n=$( echo $(( $n / 10 )) )										# integer of rounded original value
	fi
	SL[$j]=$n
}

# There may be only one partition on a host for a given topic.
# So we may have to check across multiple hosts.
# also there is an edge case where a server had to be replaced.
# this causes nearly a double sized partition for a period of time and can trigger alerts.
# however even though the partition might be twice the size of another partition,
# we don't necessarily want to escalate. If this is the case there will be a flag file to
# notify us to use the normal reduction of retention value for the partition involved.

function checkSize
{
echo "Checking sizes for $aTL"
# we need to see if partition sizes are all nearly the same or if not escalate to xAD.
	S=$( grep "/${aTL}-[0-9]" kafka_DiskUsage.out |awk '{print $1}' )						# get sizes only
	m=$( echo $S |wc -w |awk '{print $1}' )										# how many sizes do we have to compare
	if [ $m -lt 2 ]													# if only one size found
	then
		T=$aTL
		getPartitionInfo;  if [ $? -ne 0 ]; then getPartitionInfo;  jumpFail;  fi				# get partition info or die
		getBrokerIDs;      if [ $? -ne 0 ]; then getBrokerIDs;      jumpFail;  fi				# get Broker IDs or die
		Pn=$( grep "/${aTL}-[0-9]" kafka_DiskUsage.out |head -1 |awk -F\- '{print $NF}' )			# get the partition number
		Isr=$( grep "Partition: $Pn" kafka_partitionInfo.out |awk '{print $NF}' )				# get the 2 Broker IDs listed in Isr:
		BID_1=$( echo $Isr |awk -F, '{print $1}' )								# isolate the first Broker ID
		BID_2=$( echo $Isr |awk -F, '{print $2}' )								# and the second BID
		newBn=$( egrep -v '${BID_1}|${BID_2}' kafka_partitionInfo.out |head -1 |awk '{print $6}' )		# get a new Broker ID number
		if [ "$newBn" = "" ]; then exit 1; fi									# bail if nothing found.
		NHN=$( grep "^${newBn}:ec2" kafka_BIDs.out |awk -F: '{print $2}' )					# get the new hostname
		if [ "$NHN" = "" ]; then exit 1; fi									# bail if nothing found
		OHN=$HN													# save original host name
		HN=$NHN													# use new host name
		getDuInfo												# get more disk usage info for this topic from new host
		HN=$OHN													# back to the problem host
		S=$( grep "/${aTL}-[0-9]" kafka_DiskUsage.out |awk '{print $1}' )					# get Sizes for this topic
		m=$( echo $S |wc -w |awk '{print $1}' )									# number of Sizes found
		if [ $m -lt 2 ]; then  echo "Failed to get more than 1 partition";  exit 0;  fi				# verify we now have more than one size
	fi
# split size into number and scale
	j=0
	for i in $S
	do
		k=$( echo $i |wc -c )
		k=$( Calc "$k - 2" )
		SL[$j]=$( echo $i |cut -c 1-$k - )									# numeric portion
# echo "SL[$j]=${SL[$j]}  k=$k"
# even though we selected partitions to exclude fractional parts, we might get one at 10G or 11G that has another one at only 9.7G so we want to round this one.
		round
		k=$( echo $(( $k + 1 )) )
		SC[$j]=$( echo $i |cut -c ${k}- - )									# scale (K, M, or G)
# echo "SC[$j]=${SC[$j]}  k=$k"
		j=$( Calc "$j + 1" )
	done
	j=$( Calc "$j - 1" )

# compare scales. must be same or else need to escalate
	for (( i=0; i<$j; i++ ))
	do
		n=$( Calc "$i + 1" )
		if [ "${SC[$i]}" != "${SC[$n]}" ]
		then
# echo "${SC[$i]} not eq ${SC[$n]}"
			isItRebuilt
			echo "partition sizes too far apart"
			echo "Need to escalate!"
			exit 0
		fi
	done
# compare values: must be within a percentage of the largest size.
# find largest size.
	ls=${SL[0]}
	if [ "$ls" = "" ];
	then
		ls=${SL[1]}
	fi
	for (( i=1; i<$m; i++ ))
	do
		if [ $ls -lt ${SL[$i]} ]; then ls=${SL[$i]}; fi
	done
	pos=$( Calc "( $ls * $partitionSizeDelta ) / 100" )								# Percent Of Size
	lsl=$( Calc "$ls - $pos" )											# Lower Size Limit
	for (( i=0; i<$m; i++ ))
	do
		if [ ${SL[$i]} -lt $lsl ]
		then
# echo "${SL[$i]} lessthan $lsl"
			isItRebuilt
			if [ $? -eq 1 ]
			then
				echo "Need to escalate!"
				echo "partition sizes too far apart"
				exit 0
			fi
		fi
	done
}

function checkHost
{	err=0
	setVdirs
# get percent disk full information.
	getDF														# uses tryTwice
	if [ $DF -eq -1 ]
	then
		getDF													# so this makes 4 attempts
		if [ $DF -eq -1 ]
		then
			echo "Failed to get \"Disk Full\" info: DF=$DF"
			exit 1
		fi
	fi
	if [ $DF -lt $ADFL ]
	then
		echo "This disk usage shows less than ${ADFL}% used DF=${DF}%."
		echo "The alert may have already cleared."
		exit 0
	fi
	if [ $DF -gt $UDFL ]
	then
		echo "This disk is more than ${UDFL}% full. DF=${DF}%"
		echo "We can try to do the procedure, or you might want to escalate to xAd immediately."
		echo "Shall we proceed ( y or n )?"
		read Reply
		case "$Reply" in
		"n" | "N")	echo "OK - Please escalate."
				exit 0
			;;
		"y" | "Y")	echo "Proceeding"
			;;
		*)		echo "You really should quit trying to jerk my chain."
				exit 1
			;;
		esac
	fi

# get disk usage info for topic partitions.
	rm -f kafka_DiskUsage.out											# remove old file
	if [ -e "kafka_DiskUsage.out" ]; then return 1; fi
	getDuInfo
# now to check any topics that are 10G or larger for possible misconfigurations shown by radically different sizes.
	nL=$( wc -l kafka_DiskUsage.out |awk '{print $1}' )
	if [ $nL -le 1 ];  then  echo "no kafka partitions on this host.";  exit 1;  fi
# get list of topics having size in the Gb range with no fractional part ( >= 10G )
	nL2=$( Calc "$nL - 1" )
	TL=$( head -$nL2 kafka_DiskUsage.out |grep "[0-9]G " |grep -v "[0-9]\.[0-9]" |sort -u - |awk '{print $2}' |awk -F\/ '{print $NF}' )
	if [ "$TL" = "" ];  then  echo "Could not find any large partitions on this host.";  exit 1;  fi
	for i in $TL
	do
		TLl=$( echo $(( $( echo $i |awk -F\- '{print $NF}'|wc -c |awk '{print $1}' ) + 1 )) )			# TLl = length of $i string following the last '-' character
		TL1=$( echo $i |wc -c |awk '{print $1}' )								# TL1 = length of $i string
		aTLl=$( Calc "$TL1 - $TLl" )										# length of $i string up to the last '-' character
		aTL=$( echo $i |cut -c 1-$aTLl )									# aTL = topic string up to the last '-' character
		checkSize
	done
# now that we know there are no misconfiguration situations to escalate, clear out and reload DU info.
	rm -f kafka_DiskUsage.out;  if [ -e "kafka_DiskUsage.out" ]; then return 1; fi					# remove old file or return failure
	getDuInfo
echo "HN=$HN"
# get the largest disk usage topic
	getTopic
	echo "Topic: $T"
	NT=$( grep "${T}-[0-9]" kafka_DiskUsage.out |wc -l |awk '{print $1}' )						# number of entries for this topic
	if [ $NT -lt 2 ]
	then
# get list of hosts with 3 of this topic partitions for possible use in picker function.
		getPartitionInfo
		if [ !-f kafka_partitionInfo.out ]; then getPartitionInfo; fi
		if [ -f kafka_partitionInfo.out ]
		then
			getBrokerIDs
			if [ !-f kafka_BIDs.out ]; then getBrokerIDs; fi
		fi
		rm -f kafka_hosts.out
		if [ -e "kafka_hosts.out" ]; then return 1; fi
		if [ -f kafka_partitionInfo.out -a -f kafka_BIDs.out ]
		then
			for i in $( cat kafka_BIDs.out )
			do
				BID=$( echo $i |awk -F: '{print $1}' )
				NL=$( grep "Leader: ${BID}	" kafka_partitionInfo.out |wc -l |awk '{print $1}' )
				if [ $NL -ge 3 ]
				then
					echo $i>>kafka_hosts.out
					err=$(( $err | $? ))
					grep "Leader: ${BID}	" kafka_partitionInfo.out >>kafka_hosts.out
				fi
			done
		fi
	fi
	return $err
}

function picker
{	NL=$( er -e %kafka${RN} |wc -l |awk '{print $1}' )
	if [ $? -ne 0 ]
	then
		NL=$( er -e %kafka${RN} |wc -l |awk '{print $1}' )
		jumpFail
	fi
	RL=$( Calc "$RANDOM % $NL" )
	if [ -f kafka_hosts.out ]
	then
		HN=$( grep amazonaws kafka_hosts.out |head -1 |awk -F: '{print $2}' )
	else
		HN=$( er -e %kafka${RN} |head -$RL |tail -1 )
		if [ $? -ne 0 ]
		then
			HN=$( er -e %kafka${RN} |head -$RL |tail -1 )
			jumpFail
		fi
	fi
	checkHost
	return $?
}

function findHost
{	HN=$( er -e %kafka${RN} |grep $H )									# start with the hostname from the email
	if [ $? -ne 0 ];  then  HN=$( er -e %kafka${RN} |grep $H );  jumpFail;  fi				# retry on fail or die
	edc=$( tryTwice "cat /etc/defaultcluster | grep -v \"Last login\"" )
	echo "DefaultCluster: $edc"
	ZKS=$( tryTwice "er -e %${edc}:ZK_CONNECT_STRING  | grep -v \"Last login\"" )
	echo "ZooKeeperConnectString: $ZKS"
	c=0
	checkHost
	while [ $? != 0 ]
	do
		c=$( Calc "$c + 1" )
		if [ $c -eq 3 ]
		then
			echo "Did not find host with more than one $T partition"
			echo "Suggest escalate to xAD"
			echo "Alternatively, re-run the script or try manually"
			exit 0
		fi
		picker
	done
}

function getRetentionValue
{
	R3=$( tryTwice "sudo su - xad -c '${BD}/kafka-topics.sh --zookeeper $ZKS --topic $T --describe |grep \"Configs:\" '" )
	isGood=$(echo $R3 |grep "\.ms=")
	if [ "$isGood" = "" ]
	then
		R3=$(tryTwice "sudo su - xad -c 'grep log.retention.hour ${CD}/server.properties'")
		R3=$(echo $R3 |awk -F= '{print $2}')
		RV=$(Calc "$R3 * 3600000")
	else
		R3=$( echo $R3 |sed "s/.Last login.*//" )
		RV=$( echo $R3 |awk '{print $NF}' |awk -F= '{print $2}' )							# Retention Value
	fi
}

function setRetentionValue
{	echo "$( date ): I am going to change the retention time of $T from $RV to $NRV"
	SRV=$( tryTwice "sudo su - xad -c '${BD}/kafka-topics.sh --zookeeper $ZKS --topic $T --alter --config retenention.ms=${NRV} '"  )
}

function resetRV
{	echo "$( date ): I am going to restore the retention value of $T from $NRV to $RV"
	SRV=$( tryTwice "sudo su - xad -c '${BD}/kafka-topics.sh --zookeeper $ZKS --topic $T --alter --config retenention.ms=${RV} '"  )
}

function lvlUp
{	Lvl=$( Calc "$Lvl + 1" )											# adjust level up one
	HN2=$HN														# save HostName
	T2=$T														# save Topic
	RV2=$RV														# save Retention Value
	NRV2=$NRV													# save New Retention Value
}

function lvlDown
{	HN=$HN2														# restore HostName
	T=$T2														# restore Topic
	RV=$RV2														# restore Retention Value
	NRV=$NRV2													# restore New Retention Value
	Lvl=$( Calc "$Lvl - 1" )											# adjust level down one
}

function getSecs													# get number of seconds since 1/1/1900_00:00
{	ct=$( date "+%s" )
	echo "LR=$LR   ct=$ct"
}

function waitTime
{	while [ $LR -gt $ct ];  do  sleep $sleepIncrement;  getSecs;  done
}

function tryFix														# see if we can adjust the retention value
{	getRetentionValue
	NRV=$( Calc "$RV - ( ( $RV * $retentionTimeDelta ) / 100 )" )							# New Retention Value
	if [ $NRV -le 0 -o $NRV -ge $RV ]
	then
		echo "new retention not acceptable"
		echo "current value: $RV"
		echo "new retention: $NRV"
		echo "Do not know how to proceed"
		exit 1
	fi

# add comment in ticket clearly stating the "Topic", ZooKeeper String, current Retention Value, and proposed new RV
	cat <<EOT |tee -a "kafka_connect.txt"

Comment to be added to SalesForce Ticket:
        User:                           $USER
        Cluster:                        $edc
        hostname:                       $HN
        Topic:                          $T
        ZooKeeper String:               $ZKS
        Current Retention Value:        $RV
        Proposed Retention Value:       $NRV
        /data % full:                   $DF

Please cut the above information and add it as a comment in the SalesForce Ticket.
Press enter ONLY AFTER you have done that.
            ---- -----

EOT
	read Reply													# do not care what it is.
	getSecs
	ctis=$ct
	echo "$ctis" >last_run.txt

# ask the operator if OK to make change.
	cat <<EOT
I can change the RetentionValue from $RV to $NRV if you like.
(Y or N)
EOT
	read Reply
	case "$Reply" in
	"Y" | "y")	echo "Please confirm your answer again:(Y or N)"
			read Reply2
			case "$Reply2" in
			"Y" | "y")	echo "do the deed"
					setRetentionValue
				;;
			"N" | "n")	echo "Canceling the intent to make changes."
					if [ $Lvl -eq 1 ]; then exit 0; fi						# nothing more to be done
					lvlDown
					getDF
				;;
			*)		echo "STOP THAT!!!!"
					if [ $Lvl -eq 1 ]; then exit 1; fi
					lvlDown
					getDF
			esac
		;;
	"N" | "n")	echo "OK - I won't make any changes."
			if [ $Lvl -eq 1 ]; then exit 0; fi								# nothing more to be done
			lvlDown
			getDF
		;;
	*)		echo "Don't EVER do that again!!!!"
	esac
}

############################
#                          #
#  Start of main program.  #
#                          #
############################
HN=$AWSHost
B=$( tryTwice "pwd" )													# verify that we can reach this host
if [ "$B" != "/home/$USER" ];  then  echo "could not connect to $AWSHost";  exit 0;  fi					# check expected return string
H=$AWSHost														# we'll attempt to use this as our initial host
rm -f kafka_connect.txt													# remove old file for appending new info
if [ -e "kafka_connect.txt" ]; then exit 1; fi
findHost														# find host where we can verify and adjust
echo "Using kafka host $HN"												# Got a good host
tryFix															# see if we can proceed

# at this point we should have altered the retention value of the largest partition(s)
# now we wait to see if that fixes the problem.
# if after some period of time the percent full of the data volume has not dropped below 80% (the alert threshold),
# we should consider doing the same for the next largest partition(s).
# exactly what that period of time should be remains a gray area, so I will assume that after 20 minutes, we will consider this a viable option.
# but for now we want to monitor the system, to see that the size of the altered partition(s) do indeed drop.
# if they do not change, or if df %used increases, then go immediately to the next largest.

if [ $? -eq 0 ]														# test return code from tryFix
then															# good to continue
	getSecs														# get current time as seconds since 1/1/1900_00:00
	quitTime=$( Calc "$ct + $qet" )
	nextLvlT=$( Calc "$ct + $sleepTime" )
	getDF
	while [ $DF -gt $ADFL -a $ct -lt $quitTime ]
	do
		LR=$( Calc "$ct + $sleepTime" )										# set next wait time
		echo "DF=$DF %"
		waitTime												# wait for next check
		if [ $Lvl -eq 1 ]
		then
			ODF=$DF												# save previous DF
			getDF												# get new DF
			if [ $DF -ge $ODF ]										# if new DF is greater than or equal to old DF
			then
				lvlUp											# save info and bump level
				getTopic										# find next largest topic
				tryFix											# see if OK to make change
			fi
		else
			getDF												# refresh DF info
		fi
	done
	resetRV														# reset the retention value for this topic
	if [ $Lvl -eq 2 ]
	then
		lvlDown
		resetRV													# reset the retention value for this topic
	fi
	getDF
	if [ $DF -gt 0 ]
	then
		echo "Data Volume = $DF %used"										# closing display of disk usage
	fi
	if [ $DF -ge $ADFL ]
	then
		echo "Failed to reduce the data volume size below alert threshold"
		echo "Must escalate to xAd."
	fi
else															# tryFix returned error
	echo "Something went wrong. Please investigate."
	echo "Then either re-try or escalate."
fi
